{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce61493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "import gspread\n",
    "import os\n",
    "\n",
    "def connect_to_sheets(credentials_file):\n",
    "    \"\"\"\n",
    "    Establish connection to Google Sheets and return the spreadsheet object\n",
    "    \"\"\"\n",
    "    credentials = service_account.Credentials.from_service_account_file(\n",
    "        credentials_file,\n",
    "        scopes=['https://www.googleapis.com/auth/spreadsheets']\n",
    "    )\n",
    "    \n",
    "    gc = gspread.authorize(credentials)\n",
    "    spreadsheet_url = os.getenv('SPREADSHEET_URL')\n",
    "    return gc.open_by_url(spreadsheet_url)\n",
    "\n",
    "def read_worksheet_to_df(spreadsheet, worksheet_name):\n",
    "    \"\"\"\n",
    "    Read a worksheet and convert it to a pandas DataFrame\n",
    "    \"\"\"\n",
    "    worksheet = spreadsheet.worksheet(worksheet_name)\n",
    "    all_values = worksheet.get_all_values()\n",
    "    headers = all_values[0]\n",
    "    data = all_values[1:]\n",
    "    return pd.DataFrame(data, columns=headers)\n",
    "\n",
    "def standardize_dataframe(df):\n",
    "    \"\"\"\n",
    "    Standardize DataFrame by:\n",
    "    1. Converting column names to lowercase with underscores\n",
    "    2. Removing whitespace from all values\n",
    "    3. Converting all string values to lowercase\n",
    "    4. Converting numeric columns to proper number format without commas\n",
    "    \"\"\"\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Standardize column names\n",
    "    df_clean.columns = df_clean.columns.str.lower()  \n",
    "    df_clean.columns = df_clean.columns.str.strip()\n",
    "    df_clean.columns = df_clean.columns.str.replace(' ', '_')  \n",
    "    df_clean.columns = df_clean.columns.str.replace('-', '_')\n",
    "    \n",
    "    # Process each column\n",
    "    for column in df_clean.columns:\n",
    "        # First convert to string and clean\n",
    "        df_clean[column] = df_clean[column].astype(str)\n",
    "        df_clean[column] = df_clean[column].str.strip().str.lower()\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            # Remove any existing commas and convert to numeric\n",
    "            numeric_values = df_clean[column].str.replace(',', '').astype(float)\n",
    "            # If conversion successful, update the column\n",
    "            df_clean[column] = numeric_values\n",
    "        except (ValueError, TypeError):\n",
    "            # If conversion fails, keep as string\n",
    "            pass\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "def standardize_dates(df):\n",
    "    \"\"\"\n",
    "    Standardize month and date columns to datetime format.\n",
    "    Handles multiple date formats and converts to Looker-compatible formats.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    try:\n",
    "        df['date'] = pd.to_datetime(df['date'], format='%d %b %Y')\n",
    "    except ValueError:\n",
    "        try:\n",
    "            df['date'] = pd.to_datetime(df['date'], format='%d/%m/%y')\n",
    "        except ValueError:\n",
    "            df['date'] = pd.to_datetime(df['date'], format='mixed', dayfirst=True)\n",
    "    \n",
    "    # Extract standardized month (as full month name) from the date column\n",
    "    df['month'] = df['date'].dt.strftime('%b').str.lower()\n",
    "    \n",
    "    # Add month-year column in YYYY-MM format for Looker compatibility\n",
    "    df['year_month'] = df['date'].dt.strftime('%Y-%b')\n",
    "    \n",
    "    # Format the date column in YYYY-MM-DD format for Looker compatibility\n",
    "    df['date'] = df['date'].dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_sheets_data(stock_inflow_df, release_df):\n",
    "    \"\"\"\n",
    "    Process both DataFrames with standardization\n",
    "    \"\"\"\n",
    "    # Apply the standardization to both DataFrames\n",
    "    stock_inflow_df = standardize_dataframe(stock_inflow_df)\n",
    "    release_df = standardize_dataframe(release_df)\n",
    "    \n",
    "    # Apply date standardization to both DataFrames\n",
    "    stock_inflow_df = standardize_dates(stock_inflow_df)\n",
    "    release_df = standardize_dates(release_df)\n",
    "    \n",
    "    return stock_inflow_df, release_df\n",
    "\n",
    "def upload_df_to_gsheet(df, spreadsheet_id, sheet_name, credentials_file):\n",
    "    \"\"\"\n",
    "    Upload a pandas DataFrame to Google Sheets.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create a copy of the DataFrame to avoid modifying the original\n",
    "        df_copy = df.copy()\n",
    "        \n",
    "        # Convert datetime columns to string format\n",
    "        datetime_columns = df_copy.select_dtypes(include=['datetime64[ns]']).columns\n",
    "        for col in datetime_columns:\n",
    "            df_copy[col] = df_copy[col].dt.strftime('%Y-%m-%d')\n",
    "            \n",
    "        # Convert any remaining non-serializable objects to strings\n",
    "        for col in df_copy.columns:\n",
    "            if df_copy[col].dtype == 'object':\n",
    "                df_copy[col] = df_copy[col].astype(str)\n",
    "        \n",
    "        # Load credentials from service account file\n",
    "        SCOPES = ['https://www.googleapis.com/auth/spreadsheets']\n",
    "        credentials = service_account.Credentials.from_service_account_file(\n",
    "            credentials_file,\n",
    "            scopes=SCOPES\n",
    "        )\n",
    "        \n",
    "        # Build the Sheets API service\n",
    "        service = build('sheets', 'v4', credentials=credentials)\n",
    "        \n",
    "        # Convert DataFrame to values list\n",
    "        values = [df_copy.columns.values.tolist()]  # Header row\n",
    "        values.extend(df_copy.values.tolist())      # Data rows\n",
    "        \n",
    "        body = {\n",
    "            'values': values\n",
    "        }\n",
    "        \n",
    "        # Clear existing content first\n",
    "        clear_request = service.spreadsheets().values().clear(\n",
    "            spreadsheetId=spreadsheet_id,\n",
    "            range=f'{sheet_name}!A1:ZZ'\n",
    "        )\n",
    "        clear_request.execute()\n",
    "        \n",
    "        # Update the sheet with new values\n",
    "        result = service.spreadsheets().values().update(\n",
    "            spreadsheetId=spreadsheet_id,\n",
    "            range=f'{sheet_name}!A1',\n",
    "            valueInputOption='RAW',\n",
    "            body=body\n",
    "        ).execute()\n",
    "        \n",
    "        print(f\"Updated {result.get('updatedCells')} cells\")\n",
    "        return True\n",
    "        \n",
    "    except HttpError as error:\n",
    "        print(f\"An error occurred: {error}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def main():\n",
    "    # Get credentials file path\n",
    "    CREDENTIALS_FILE = 'credentials.json' \n",
    "    \n",
    "    try:\n",
    "        # Connect to Google Sheets\n",
    "        spreadsheet = connect_to_sheets(CREDENTIALS_FILE)\n",
    "        \n",
    "        # Read worksheets\n",
    "        stock_inflow_df = read_worksheet_to_df(spreadsheet, 'stock_inflow_')\n",
    "        release_df = read_worksheet_to_df(spreadsheet, 'release')\n",
    "        \n",
    "        # Process the data\n",
    "        stock_inflow_df, release_df = process_sheets_data(stock_inflow_df, release_df)\n",
    "        \n",
    "        # Upload processed data to new sheets\n",
    "        spreadsheet_id = os.getenv('SPREADSHEET_ID')\n",
    "        \n",
    "        # Upload stock inflow data\n",
    "        success_stock = upload_df_to_gsheet(\n",
    "            stock_inflow_df, \n",
    "            spreadsheet_id, \n",
    "            'stock_inflow_clean',\n",
    "            CREDENTIALS_FILE\n",
    "        )\n",
    "        \n",
    "        # Upload release data\n",
    "        success_release = upload_df_to_gsheet(\n",
    "            release_df, \n",
    "            spreadsheet_id, \n",
    "            'release_clean',\n",
    "            CREDENTIALS_FILE\n",
    "        )\n",
    "        \n",
    "        if success_stock and success_release:\n",
    "            print(\"Data processing and upload completed successfully!\")\n",
    "        else:\n",
    "            raise Exception(\"Failed to upload one or both datasets\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
