{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a72e639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "import gspread\n",
    "import os\n",
    "\n",
    "def connect_to_sheets(credentials_file):\n",
    "    credentials = service_account.Credentials.from_service_account_file(\n",
    "        credentials_file,\n",
    "        scopes=['https://www.googleapis.com/auth/spreadsheets']\n",
    "    )\n",
    "    \n",
    "    gc = gspread.authorize(credentials)\n",
    "    spreadsheet_url = os.getenv('SPREADSHEET_URL')\n",
    "    return gc.open_by_url(spreadsheet_url)\n",
    "\n",
    "def read_worksheet_to_df(spreadsheet, worksheet_name):\n",
    "    worksheet = spreadsheet.worksheet(worksheet_name)\n",
    "    all_values = worksheet.get_all_values()\n",
    "    headers = all_values[0]\n",
    "    data = all_values[1:]\n",
    "    return pd.DataFrame(data, columns=headers)\n",
    "\n",
    "def separate_opening_stock(df):\n",
    "    opening_stock_mask = df['purchasing_officer'].str.contains('opening stock', case=False, na=False)\n",
    "    opening_stock_df = df[opening_stock_mask].copy()\n",
    "    main_df = df[~opening_stock_mask].copy()\n",
    "    return main_df, opening_stock_df\n",
    "\n",
    "def standardize_dataframe(df):\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    df_clean.columns = df_clean.columns.str.lower()  \n",
    "    df_clean.columns = df_clean.columns.str.strip()\n",
    "    df_clean.columns = df_clean.columns.str.replace(' ', '_')  \n",
    "    df_clean.columns = df_clean.columns.str.replace('-', '_')\n",
    "    \n",
    "    for column in df_clean.columns:\n",
    "        df_clean[column] = df_clean[column].astype(str)\n",
    "        df_clean[column] = df_clean[column].str.strip().str.lower()\n",
    "        \n",
    "        try:\n",
    "            numeric_values = df_clean[column].str.replace(',', '').astype(float)\n",
    "            df_clean[column] = numeric_values\n",
    "        except (ValueError, TypeError):\n",
    "            pass\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "def standardize_dates(df):\n",
    "    if df.empty:\n",
    "        return df\n",
    "        \n",
    "    df = df.copy()\n",
    "    \n",
    "    try:\n",
    "        df['date'] = pd.to_datetime(df['date'], format='%d %b %Y')\n",
    "    except ValueError:\n",
    "        try:\n",
    "            df['date'] = pd.to_datetime(df['date'], format='%d/%m/%y')\n",
    "        except ValueError:\n",
    "            df['date'] = pd.to_datetime(df['date'], format='mixed', dayfirst=True)\n",
    "    \n",
    "    df['month'] = df['date'].dt.strftime('%b').str.lower()\n",
    "    df['year_month'] = df['date'].dt.strftime('%Y-%b')\n",
    "    df['date'] = df['date'].dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_summary_df(stock_inflow_df, release_df):\n",
    "    summary_df = pd.DataFrame()\n",
    "    \n",
    "    # Get unique months from both dataframes\n",
    "    inflow_months = set(stock_inflow_df['month'].unique())\n",
    "    release_months = set(release_df['month'].unique())\n",
    "    all_months = sorted(list(inflow_months.union(release_months)))\n",
    "    \n",
    "    # Get unique year_months from both dataframes\n",
    "    inflow_year_months = set(stock_inflow_df['year_month'].unique())\n",
    "    release_year_months = set(release_df['year_month'].unique())\n",
    "    all_year_months = sorted(list(inflow_year_months.union(release_year_months)))\n",
    "    \n",
    "    # Create base dataframe with all months\n",
    "    summary_df = pd.DataFrame({\n",
    "        'month': all_months,\n",
    "        'year_month': all_year_months\n",
    "    })\n",
    "    \n",
    "    # Calculate chicken inflow summaries\n",
    "    chicken_inflow = stock_inflow_df[stock_inflow_df['product_type'] == 'chicken'].groupby('month').agg({\n",
    "        'quantity': 'sum',\n",
    "        'weight': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Calculate chicken release summaries\n",
    "    chicken_release = release_df[release_df['product'] == 'chicken'].groupby('month').agg({\n",
    "        'quantity': 'sum',\n",
    "        'weight_in_kg': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Calculate gizzard inflow summaries\n",
    "    gizzard_inflow = stock_inflow_df[stock_inflow_df['product_type'] == 'gizzard'].groupby('month').agg({\n",
    "        'weight': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Calculate gizzard release summaries\n",
    "    gizzard_release = release_df[release_df['product'] == 'gizzard'].groupby('month').agg({\n",
    "        'weight_in_kg': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Merge all data with the summary dataframe\n",
    "    summary_df = summary_df.merge(chicken_inflow, on='month', how='left')\n",
    "    summary_df = summary_df.merge(\n",
    "        chicken_release.rename(columns={\n",
    "            'quantity': 'total_chicken_release_quantity',\n",
    "            'weight_in_kg': 'total_chicken_release_weight'\n",
    "        }), \n",
    "        on='month', \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    summary_df = summary_df.merge(\n",
    "        gizzard_inflow.rename(columns={'weight': 'total_gizzard_inflow_weight'}),\n",
    "        on='month',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    summary_df = summary_df.merge(\n",
    "        gizzard_release.rename(columns={'weight_in_kg': 'total_gizzard_release_weight'}),\n",
    "        on='month',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Rename columns\n",
    "    summary_df = summary_df.rename(columns={\n",
    "        'quantity': 'total_chicken_inflow_quantity',\n",
    "        'weight': 'total_chicken_inflow_weight'\n",
    "    })\n",
    "    \n",
    "    # Fill NaN values with 0\n",
    "    numeric_columns = summary_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    summary_df[numeric_columns] = summary_df[numeric_columns].fillna(0)\n",
    "    \n",
    "    # Round numeric columns to 2 decimal places\n",
    "    summary_df[numeric_columns] = summary_df[numeric_columns].round(2)\n",
    "    \n",
    "    # Reorder columns to match desired output\n",
    "    column_order = [\n",
    "        'month',\n",
    "        'year_month',\n",
    "        'total_chicken_inflow_quantity',\n",
    "        'total_chicken_inflow_weight',\n",
    "        'total_chicken_release_quantity',\n",
    "        'total_chicken_release_weight',\n",
    "        'total_gizzard_inflow_weight',\n",
    "        'total_gizzard_release_weight'\n",
    "    ]\n",
    "    \n",
    "    summary_df = summary_df[column_order]\n",
    "    \n",
    "    return summary_df\n",
    "\n",
    "def process_sheets_data(stock_inflow_df, release_df):\n",
    "    stock_inflow_df = standardize_dataframe(stock_inflow_df)\n",
    "    release_df = standardize_dataframe(release_df)\n",
    "    \n",
    "    stock_inflow_main_df, opening_stock_df = separate_opening_stock(stock_inflow_df)\n",
    "    \n",
    "    release_df = release_df[~release_df['name_of_collector'].str.contains('opening stock', case=False, na=False)]\n",
    "    \n",
    "    # Set quantity to 0 for gizzard products\n",
    "    release_df.loc[release_df['product'].str.contains('gizzard', case=False, na=False), 'quantity'] = 0\n",
    "    \n",
    "    stock_inflow_main_df = standardize_dates(stock_inflow_main_df)\n",
    "    opening_stock_df = standardize_dates(opening_stock_df)\n",
    "    release_df = standardize_dates(release_df)\n",
    "    \n",
    "    summary_df = create_summary_df(stock_inflow_main_df, release_df)\n",
    "    \n",
    "    return stock_inflow_main_df, opening_stock_df, release_df, summary_df\n",
    "\n",
    "def upload_df_to_gsheet(df, spreadsheet_id, sheet_name, credentials_file):\n",
    "    try:\n",
    "        df_copy = df.copy()\n",
    "        \n",
    "        # Format datetime columns\n",
    "        datetime_columns = df_copy.select_dtypes(include=['datetime64[ns]']).columns\n",
    "        for col in datetime_columns:\n",
    "            df_copy[col] = df_copy[col].dt.strftime('%Y-%m-%d')\n",
    "        \n",
    "        # Ensure numeric columns are formatted properly\n",
    "        numeric_columns = df_copy.select_dtypes(include=['float64', 'int64']).columns\n",
    "        for col in numeric_columns:\n",
    "            df_copy[col] = pd.to_numeric(df_copy[col], errors='coerce').fillna(0)\n",
    "        \n",
    "        SCOPES = ['https://www.googleapis.com/auth/spreadsheets']\n",
    "        credentials = service_account.Credentials.from_service_account_file(\n",
    "            credentials_file,\n",
    "            scopes=SCOPES\n",
    "        )\n",
    "        \n",
    "        service = build('sheets', 'v4', credentials=credentials)\n",
    "        \n",
    "        values = [df_copy.columns.values.tolist()]\n",
    "        values.extend(df_copy.values.tolist())\n",
    "        \n",
    "        body = {\n",
    "            'values': values\n",
    "        }\n",
    "        \n",
    "        # Clear existing content\n",
    "        clear_request = service.spreadsheets().values().clear(\n",
    "            spreadsheetId=spreadsheet_id,\n",
    "            range=f'{sheet_name}!A1:ZZ'\n",
    "        )\n",
    "        clear_request.execute()\n",
    "        \n",
    "        # Update with new content\n",
    "        result = service.spreadsheets().values().update(\n",
    "            spreadsheetId=spreadsheet_id,\n",
    "            range=f'{sheet_name}!A1',\n",
    "            valueInputOption='USER_ENTERED',\n",
    "            body=body\n",
    "        ).execute()\n",
    "        \n",
    "        # Get sheet ID\n",
    "        sheet_metadata = service.spreadsheets().get(spreadsheetId=spreadsheet_id).execute()\n",
    "        sheet_id = None\n",
    "        for sheet in sheet_metadata.get('sheets', ''):\n",
    "            if sheet.get('properties', {}).get('title') == sheet_name:\n",
    "                sheet_id = sheet.get('properties', {}).get('sheetId')\n",
    "                break\n",
    "        \n",
    "        if sheet_id is not None:\n",
    "            requests = [{\n",
    "                'repeatCell': {\n",
    "                    'range': {\n",
    "                        'sheetId': sheet_id,\n",
    "                        'startRowIndex': 1,\n",
    "                        'startColumnIndex': 2,  # Start from the first numeric column\n",
    "                        'endColumnIndex': len(df_copy.columns)\n",
    "                    },\n",
    "                    'cell': {\n",
    "                        'userEnteredFormat': {\n",
    "                            'numberFormat': {\n",
    "                                'type': 'NUMBER',\n",
    "                                'pattern': '#,##0.00'\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "                    'fields': 'userEnteredFormat.numberFormat'\n",
    "                }\n",
    "            }]\n",
    "            \n",
    "            # Apply the formatting\n",
    "            format_body = {'requests': requests}\n",
    "            service.spreadsheets().batchUpdate(\n",
    "                spreadsheetId=spreadsheet_id,\n",
    "                body=format_body\n",
    "            ).execute()\n",
    "        \n",
    "        print(f\"Updated {result.get('updatedCells')} cells in {sheet_name}\")\n",
    "        return True\n",
    "        \n",
    "    except HttpError as error:\n",
    "        print(f\"An error occurred in {sheet_name}: {error}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred in {sheet_name}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def main():\n",
    "    CREDENTIALS_FILE = 'credentials.json' \n",
    "    \n",
    "    try:\n",
    "        spreadsheet = connect_to_sheets(CREDENTIALS_FILE)\n",
    "        \n",
    "        stock_inflow_df = read_worksheet_to_df(spreadsheet, 'stock_inflow')\n",
    "        release_df = read_worksheet_to_df(spreadsheet, 'release')\n",
    "        \n",
    "        stock_inflow_main_df, opening_stock_df, release_df, summary_df = process_sheets_data(stock_inflow_df, release_df)\n",
    "        \n",
    "        spreadsheet_id = os.getenv('SPREADSHEET_ID')\n",
    "        \n",
    "        success_stock = upload_df_to_gsheet(\n",
    "            stock_inflow_main_df, \n",
    "            spreadsheet_id, \n",
    "            'stock_inflow_clean',\n",
    "            CREDENTIALS_FILE\n",
    "        )\n",
    "        \n",
    "        success_opening_stock = upload_df_to_gsheet(\n",
    "            opening_stock_df, \n",
    "            spreadsheet_id, \n",
    "            'opening_stock',\n",
    "            CREDENTIALS_FILE\n",
    "        )\n",
    "        \n",
    "        success_release = upload_df_to_gsheet(\n",
    "            release_df, \n",
    "            spreadsheet_id, \n",
    "            'release_clean',\n",
    "            CREDENTIALS_FILE\n",
    "        )\n",
    "        \n",
    "        success_summary = upload_df_to_gsheet(\n",
    "            summary_df,\n",
    "            spreadsheet_id,\n",
    "            'summary',\n",
    "            CREDENTIALS_FILE\n",
    "        )\n",
    "        \n",
    "        if success_stock and success_opening_stock and success_release and success_summary:\n",
    "            print(\"Data processing and upload completed successfully!\")\n",
    "        else:\n",
    "            raise Exception(\"Failed to upload one or more datasets\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
